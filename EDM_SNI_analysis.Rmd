---
title: "Dynamic Species Interactions in the San Nicolas Island Kelp Forest"
subtitle: "Empirical dynamic modeling analysis"
author: "Owen Liu"
date: "March 13, 2018"
output: html_document
bibliography: citation_bibtex.bib
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE,message=F}
# Load required packages
require(tidyverse)
require(rEDM)
require(quantreg)
require(knitr)
require(extrafont)
```

## Introduction

This document accompanies the manuscript "..." The following analyses lay out the building blocks of the empirical dynamic modeling approach [@Deyle2016; @Chang2017] that produced the final version of the analyses in the paper.

In the analysis that follows, in each step that involves a new type of EDM method, its logic will be briefly described.  However, keep in mind that the basic theory behind each individual method is the same: We use some dynamic information (from single or multiple time series) to reconstruct a shadow attractor, and then use the properties of that manifold to make predictions.

## 1. Variables in the Data

### The San Nicolas Island Dataset

San Nicolas Island is a small, remote island situated about 100 kilometers offshore from southern California.  The island itself is small, about 14 kilometer long and 5 km wide. The data in the analysis is from a sampling station on the western end of San Nicolas Island. The benthic monitoring data herein have been collected more or less every six months for more than 35 years by the USGS and its Western Ecological Research Center (USGS-WERC), and in 2013 the datasets were made available publicly through Ecological Archives:

Michael C. Kenner, James A. Estes, M. Tim Tinker, James L. Bodkin, Robert K. Cowen, Christopher Harrold, Brian B. Hatfield, Mark Novak, Andrew Rassweiler, and Daniel C. Reed. 2013. A multi-decade time series of kelp forest community structure at San Nicolas Island, California (USA). Ecology 94:2654. http://dx.doi.org/10.1890/13-0561.1

And in 2016, the data were again compiled and an updated version was published online:

Miller R., A. Rassweiler, D. Reed, K. Lafferty, L. Kui, M. O'Brien. 2016. Santa Barbara Channel Marine BON: Integrated quad and swath cover. Environmental Data Initiative.

### Physical Oceanographic Data

A body of other research has established that a combination of physical forcing (waves, storms), temperature, and lower frequency climate modes (e.g., El Ninos) have an important influence on the dynamics of kelp forests [@Reed2011; @Cavanaugh2011; @Bell2015,@Young2015]. With these data, we can draw connections between the physical variables and the species interactions in our constrained trophic web.

We have four datasets, already processed into the same time frame (periods) as the SNI benthic monitoring data:

* **[The Multivariate ENSO index (MEI)](http://www.esrl.noaa.gov/psd/enso/mei)**
    + The first principal component of a composite set of physical parameters
    + Positive values of the MEI index are generally associated with El Nino conditions, decreases in wind-driven upwelling, warmer surface waters and nutrient-poor conditions
    + Variable here is the average index value for the four months preceding each Spring or Fall monitoring period (i.e., December to March or June to September, respectively)
    
* **[The Pacific Decadal Oscillation index (PDO)](http://research.jisao.washington.edu/pdo/)**
    + Leading empirical orthogonal function (EOF) of monthly sea surface temperature anomalies (SST-A) over the North Pacific (poleward of 20Â° N) after the global average sea surface temperature has been removed
    + Positive PDO values indicate warmer SST, and nutrient-poor conditions along the western coast of the contiguous United States
    + Aggregated and averaged the same way as MEI
    
* **[The North Pacific Gyre Oscillation (NPGO)](http://www.o3d.org/npgo/)**
    + From [@DiLorenzo2008]
    + Climate pattern that emerges as the 2nd dominant mode of sea surface height variability (2nd EOF SSH) in the Northeast Pacific
    + Better correlated with salinity, nutrients, and chlorophyll than PDO, showing forcing for the planktonic community
    + Strong predictor of upwelling cells south of 38 deg N
    + Aggregated and averaged the same way as MEI and PDO
    
* **Sea surface temperature (SST)**
    + Two sources (to fill in data gaps):
      + Sea surface temperature data directly from Begg Rock and San Nicolas Island buoys, from the [Coastal Data Information Program (CDIP)](http://cdip.ucsd.edu)
      + NOAA's [Optimally Interpolated Sea Surface Temperature](https://www.ncdc.noaa.gov/oisst)
    + Similar to the above, value is an average SST for the four months preceding each period
* **Maximum significant wave height (Hs)**
    + Combined data from the Begg and SNI buoys with modeled data from the [Geophysical Fluid Dynamics Laboratory](http://cmgwindwave.usgsportals.net/)
    + Signficant wave height is defined as the average height, in meters, of the one third highest waves in the record
    + Instead of an average, value here is the maximum significant wave height of the four months preceding each period. This is meant to capture any large storm events, as well as general level of physical disturbance

Unlike the biological data, where there are unique spatial replicates, the physical data have only one value for each of the 69 monitoring periods, and hence their values are replicated (copied) for each site to match the total length of the biological data.

#### Note about data processing

Usual best practice for EDM is to create normalized time series, so that state-space reconstructions are not distorted by differences in orders of magnitude between variables. In addition, in this study we concatenate each species/station/swath time series into one long time series for each species, while preserving a time indicator (variable 'period') and a site identifier, to ensure that we do not "cross" the boundaries of replicate time series in analyses. Empirical dynamic modeling can use multiple spatial replicates in lieu of increased length of individual time series, to maximize the dynamic information that can be drawn from the system [@Hsieh2008;@Clark2015;@Chang2017].

All raw data is available online or in the included files. We join the monitoring and physical datasets and normalized all time series (see scripts in the "data" folder for details:

```{r load data,message=FALSE,echo=F}
source("data/data preparation scripts/produce_final_data.R")
```

```{r list of variables,echo=F,fig.cap="List of variables"}
tibble(Variable=colnames(westend),Description=c("Monitoring Transect","Monitoring Period","Laminaria Normalized Density",
                                            "Macrocystis pyrifera >1m Normalized Density","Pterygophora Normalized Density",
                                            "Strongylocentrotus purpuratus Normalized Density","Mesocentrotus franciscanus Normalized Density",
                                            "Macrocystis pyrifera <1m Normalized Density","Normalized Multivariate ENSO Index",
                                            "Normalized Pacific Decadal Oscillation","Normalized North Pacific Gyre Oscillation",
                                            "Normalized Maximum Significant Wave Height","Normalized Sea Surface Temperature")) %>%
  knitr::kable()
```


```{r mean density over time, echo=F,message=F}
# Species naming key for use in plotting
namekey <- tibble(dataset=c(rep("Benthic density",6),rep("Physical",5)),short=names(westend[3:13]),
                  long=c("Laminaria","Macrocystis >1m","Pterygophora","Purple urchin","Red urchin","Macrocystis <1m","Multivariate ENSO Index","Pacific Decadal Oscillation","North Pacific Gyre Oscillation","Significant Wave Height","Sea Surface Temperature"),plotting=c("L. far","M. pyr","P. cal","S. pur","M. fra","M. pyr (j)","(P) MEI","(P) PDO","(P) NPGO","(P) Max Hs","(P) SST"))

namekey <- bind_rows(namekey, data_frame(long="NA",dataset="NA",short="const",plotting="Constant")) %>%
  
  # define column "plotting" as a factor so we can later control plotting order on figures
  mutate(plotting=factor(plotting,levels=c("(P) MEI","(P) PDO","(P) NPGO","(P) Max Hs","(P) SST","L. far","M. pyr","M. pyr (j)","P. cal","S. pur","M. fra","Constant")))


# key relating monitoring period to its year/month
period.key <- data_frame(year=rep(1980:2014,each=12),month=rep(1:12,35),period=c(rep(NA,8),rep(1,4),rep(2:69,each=6)))
periods.first <- period.key %>% 
  distinct(period,.keep_all=T) %>%
  mutate(day=1) %>% #assume all monitoring done on first day of month
  unite(date_str,year,month,day,sep="-") %>%
  mutate(date_str=ymd(date_str))

westend.long <- westend %>%
  gather(key=spp,value=dens,-period,-site,na.rm=T) %>%
  left_join(namekey, by=c("spp"="short"))
westend.meandens <- westend.long %>%
  group_by(spp,period,long) %>% 
  summarise(meandens=mean(dens,na.rm=T),sddens=sd(dens,na.rm=T))%>%
  mutate(lower=meandens-sddens,upper=meandens+sddens)%>%
  left_join(periods.first,by="period") %>%
  ungroup()

# position adjustment for visual clarity
pd <- position_dodge(width=100)
westend.mean_dens_plot <- westend.meandens %>%
  filter(spp %in% c("mac","red","pter","ymac","purp","lam")) %>%
  mutate(type=ifelse(spp %in% c("mac","ymac","pter","lam"),"algae","urchin")) %>%
  ggplot(aes(x=date_str,y=meandens,col=long,linetype=type))+
      geom_hline(yintercept=0)+
      geom_line(lwd=2,alpha=0.8,position=pd)+
      geom_pointrange(aes(ymin=lower,ymax=upper),size=0.3,position=pd)+
      xlab("Year")+ylab("Normalized Density")+
      scale_color_manual(values=c("navyblue","gray50","darkgreen","darkcyan","mediumpurple4","darkred"),
                         guide=guide_legend(title="Species",override.aes = list(size=1)))+
      guides(linetype="none")+
      theme_minimal()+
      theme(text = element_text(family="Rockwell",size=16),
            legend.position = c(0.15,0.8),
            legend.text = element_text(size=12))
westend.mean_dens_plot
rm(pd,period.key,periods.first,westend.long,westend.meandens)
```

***

## 2. Establishing Univariate Predictability and Nonlinearity

For each of these time series, we have a few steps to see if they seem appropriate to analyze together with EDM techniques [@Chang2017]. We want to be careful that our state space reconstructions are reliable and represent valid manifolds. In other words, we don't want to rely on simple cross-correlation or the prior knowledge that all these data were collected around the same locations at around the same times. We want evidence that:

1. Variables can be probably embedded (i.e., they show evidence of limited system dimensionality)
2. Variables display state-dependent (nonlinear) dynamics, and therefore that nonlinear (EDM) methods are appropriate for analysis of these data

First, we use simplex projection to get a sense of system dimensionality for each variable, which will also give us an idea of the appropriate embedding dimension to use in later analyses. Then, we explicitly look for evidence of state-dependence and nonlinear dynamics with a prediction horizon test and S-maps.

***
```{r time series segments, include=F}
# segments of the time series (which rows of the data are individual transects?)
westend_segs_sites <- westend %>%
  ungroup() %>%
  mutate(ind = row_number()) %>% 
  group_by(site) %>%
  summarise(first=first(ind),last=last(ind))

# Time series segments without site identifier. We'll need this later
westend.segs <- select(westend_segs_sites,-site)

# species in the study
study_spp <- c("red","purp","lam","pter","mac","ymac")
# physical variables in the study
phys.vars <- c("mei","pdo","npgo","waves","sst")
```

***

### Simplex Projection and Embedding Dimensions

For each species/variable separately, we will search for signals of deterministic behavior using simplex projection. In simplex projection, we first reconstruct a shadow attractor in *E* dimensions, where *E* is the number of variables, or number of progressive lags of a single variable used in the reconstruction. *E* is called the __*embedding dimension*__. The *E*-length vectors, for example $\it{\bf{x_{t}}} = <x_t,x_{t-1},x_{t-2}>$ are points on the attractor, and the set of *E*-length vectors used for the reconstruction is called the __*library*__. To predict $\it{\bf{x_{t+1}}}$, the simplex algorithm finds the *E* +1 nearest neighbors of $\it{\bf{x_{t}}}$ in the state space, and the prediction $\it{\bf{\hat{x}_{t+1}}}$ is the average of the nearest neighbors' values at $\it{t+1}$, weighted by their Euclidean distance from $\it{\bf{x_{t}}}$ at $\it{t}$. This is the essence of simplex projection: a forecast for a given point in state space is surmised from the forward trajectories of observed nearby points.

In descriptive terms, this is akin to asking, "When the system has been in a state like this before, what happened next?" For example, if we are interested in predicting *Macrocystis* density next year, we might take the current three-year density trend (this year, last year, and the year before, *E*=3) and compare it to a subset of times in the past when successive three-year dynamics looked similar to that set of points. Our prediction, logically, would be the average of that subset, projected foreward one year and weighted by their similarity to the current trend.

By varying the value of *E*, we can determine what the best embedding dimension is for each variable in our analysis, essentially a proxy for the number of variables that best "unfolds" or best represents the shadow attractor. We can measure the skill of an embedding by comparing the estimated forecasts $\it{\bf{\hat{x}_{t+1}}}$ with the observed values $\it{\bf{x_{t+1}}}$, and we report it with $\it{\bf{\rho}}$, the Pearson correlation coefficient between predictions and observations. To avoid in-sample fitting, we use a leave-one-out cross-validation scheme, removing one vector at a time from the library, and predicting its dynamics from the other library vectors.

```{r univariate simplex westend,fig.height=10,fig.width=7,echo=F}
# List to store output of simplex projection
westend.simp.list <- list()

# Run simplex projection for each species at each site, and plot output
par(mfrow=c(3,2))
for(i in 1:length(study_spp)) {
  spp <- study_spp[i]
  dat <- westend %>% select(matches(spp)) %>% as.data.frame()
  out <- simplex(as.numeric(dat[,1]),lib=as.matrix(westend.segs),E=2:15,silent=T)
  westend.simp.list[[spp]] <- out
  
  # Plot embedding dimension vs. predictive ability (rho)
  plot(out$E,out$rho,type="l",main=namekey$long[match(spp,namekey$short)],
       ylim=c(0,1),
       xlab="Embedding Dimension (E)",ylab=expression(paste("Skill, ",rho)))
}

# Save best embedding dimensions
westend.bestE <- sapply(westend.simp.list,function(x) {
  temp <- x %>% filter(!is.na(rho))
  temp$E[temp$rho==max(temp$rho)]
})

# on looking at the graph, manually change embedding dimension for macrocystis and pterygophora to one that has a very similar
# predictability, but will let us make use of more data

westend.bestE["mac"] <- 6
westend.bestE["ymac"] <- 8
westend.bestE["pter"] <- 6

rm(spp,dat,out)

# Run simplex for each physical variable
par(mfrow=c(3,2))
phys.simp.list <- list()
for(i in 1:length(phys.vars)) {
  ind <- phys.vars[i]
  dat <- westend %>% select(matches(ind)) %>% as.data.frame()
  out <- simplex(as.numeric(dat[,1]),lib=c(1,69),E=2:10,silent=T)
  phys.simp.list[[ind]] <- out
  westend.simp.list[[ind]] <- out

  # Plot embedding dimension vs. predictive ability (rho)
  plot(out$E,out$rho,type="l",main=namekey$long[match(ind,namekey$short)],xlab="Embedding Dimension (E)",ylab=expression(paste("Skill, ",rho)))
}
rm(ind,dat,out)
phys.bestE <- sapply(phys.simp.list,function(x) {
  temp <- x %>% filter(!is.na(rho))
  temp$E[temp$rho==max(temp$rho)]
})

westend.bestE <- c(westend.bestE,phys.bestE)
```

***

### Prediction Horizon test

We also want to look at prediction decay for each variable, which is one piece of evidence that a dynamic system is nonlinear. Using the best *E* identified in the previous step, we attempt to make predictions increasing far into the future, instead of just one period ahead. A nonlinear system should show decreasing predictive power with increasing prediction horizon[@Sugihara1994]. This phenomenon is a property of deterministic chaos and is analagous to the "butterfly effect", where in a nonlinear system, trajectories in state-space are expected to diverge over time. To examine this effect, we hold *E* constant, and proceed with simplex projection as before, but varying the prediction horizon, $t_p$ (i.e., how many steps ahead we try to predict).

```{r prediction horizon test,message=F,echo=F,fig.height=10,fig.width=7,echo=F}
# List to hold prediction horizon results
westend.tp.list <- list()

par(mfrow=c(3,2))
for(i in 1:length(study_spp)) {
  spp <- study_spp[i]
  dat <- westend %>% select(matches(spp)) %>% as.data.frame()
  out <- simplex(as.numeric(dat[,1]),lib=as.matrix(westend.segs),silent=T,E=westend.bestE[spp],tp=1:10)
  westend.tp.list[[spp]] <- out
  
  # Plot time horizon vs. predictive ability (rho)
  plot(out$tp,out$rho,type="l",main=namekey$long[match(spp,namekey$short)],xlab="Time to Prediction",ylab=expression(paste("Skill, ",rho)))
}
rm(spp,dat,out)
```

The prediction horizon effect check is promising overall, as most variables decline in predictive ability with increasing time horizon. For *Pterygophora californica*, there is some evidence of cyclic behavior, in that dynamics are more predictable 6 periods in the future than 3 or 4 periods. This is something to be mindful of, but we leave *Pterygophora* in our analysis for now.

***

### S-maps for Each Species

All of the variables show a decent ability to self-predict, as shown by simplex projection, although some variables require rather high embedding dimensions, indicative of higher-dimensionality dynamics. However, the butterfly effect check is evidence of potential nonlinearity, as all variables decline in predictive ability with time horizon.

We can look for further evidence of nonlinearity with S-maps. S-maps is short for "sequentially weighted global linear maps", and it is similar to simplex projection, except instead of using just the *E* +1 nearest neighbors to make forecasts, S-maps uses all library vectors, and exponentially weights them by their distance to the prediction vector before using linear regression to make a forecast. A parameter, $\it{\bf{\theta}}$, tunes how much greater weight is given to nearby points. If $\it{\bf{\theta}}=0$, all library vectors are weighted equally, and the resulting model is just a vector autogressive (VAR) model of order *E*. However, as $\it{\bf{\theta}}$ is tuned above 0, nearby points in state-space are given more weight in forecasts. Therefore, if model skill $\it{\bf{\rho}}$ increases with increasing $\it{\bf{\theta}}$, it is evidence of nonlinear, state-dependent dynamics. For a more formal description of the S-maps procedure, see @Sugihara1994 and @Deyle2016.

As a side note, with $\it{\bf{\theta}}>0$, although the set library vectors remains constant, the *weights* given to library vectors for regression is specific to each point in state-space, and therefore a separate linear map is created for each predicted vector. This is why the procedure is called "sequentially weighted global linear maps". Conceptually, as the dynamic system moves along the surface of the attractor, S-maps sequentially computes linear maps to the next point based on nearby points.

For prediction of each variable using S-maps, we can again use the optimal embedding dimension, *E*, found through our simplex projection above, and we plot the tuning parameter $\it{\bf{\theta}}$ against $\it{\bf{\rho}}$ to look for evidence of nonlinear dynamics.

```{r univariate s_maps westend,fig.height=10,fig.width=7,echo=F}
westend.smap.list <- list() # list to store output

par(mfrow=c(3,2))
for(i in 1:length(study_spp)) {
  spp <- study_spp[i]
  dat <- westend %>% select(matches(spp)) %>% as.data.frame()
  out <- s_map(as.numeric(dat[,1]),lib=as.matrix(westend.segs),E=westend.bestE[spp],silent=T)
  westend.smap.list[[spp]] <- out
  
  # Plot theta dimension vs. predictive ability (rho)
  plot(out$theta,out$rho,type="l",main=namekey$long[match(spp,namekey$short)],xlab=expression(paste("Nonlinearity (",theta,")")), ylab=expression(paste("Skill, ",rho)))
}
rm(spp,dat,out)
```

All variables show significantly improved predictive ability with increased theta, suggesting nonlinear dynamics. Together, the simplex, prediction horizon, and S-map results suggest our approach is valid--variables are predictable, and most predictable in a nonlinear manner.

## 2. Convergent Cross Mapping

Generalizations of Takens' theorem indicate that if two variables (in our case, species or physical variables) are part of the same dynamic system, their individual dynamics should reflect their relative causal influence [@Sugihara2012; @Deyle2013,@Ye2015,@Clark2015]. In other words, if one variable (for example, giant kelp), is casually forced by another (sea urchins), that forcing should leave a signature on the giant kelp time series. Convergent cross mapping (CCM) tests for causation by using the attractor/manifold built from the time series of one variable to predict another. CCM works just like univariate simplex projection that we did in Step 1, except that separate variables are used for library and prediction vectors. In addition, we normally predict contemporaneous values of the other variable, instead of projecting one step forward (prediction horizon $t_{p}=0$). If the attractor can accurately (based on out-of-sample prediction skill, just as before) predict the dynamics of the second variable, we can claim that the second variable has a causal influence on the first.  In other words, the *causal effect of A on B is determined by how well B cross-maps A*. In this way, the inference from cross-mapping is the converse direction of causation. In our example, if sea urchins drive giant kelp,the dynamic information from the urchin time series should be reflected in the kelp dynamics, and kelp should significantly cross-map the urchins.

Cross-mapping can distinguish unidirectional forcing (A forces B but B does not force A) from bi-directional (A and B force each other). It can also resolve transitive causal chains (A causes B causes C, see Fig. 4 in @Sugihara2012). To look for a causal signal, we plot predictive skill  $\it{\bf{\rho}}$ against library size (the number of embedded vectors used to construct the attractor). There are two criteria for CCM to establish causality: 
* First, and most obviously, predictive cross-map skill using all available data should be significantly greater than zero. 
* Second, that predictability should be convergent.  Convergence means that cross-mapped estimates improve with library length, because the attractor is more fully resolved and therefore estimation error should decline. Convergence is key to distinguishing causation from simple correlation.

The CCM algorithm uses a random sampling method to test multiple "versions" of each library size, sampling a subset from the supplied library vectors to give a sense of the confidence intervals around prediction skill. We again use leave-one-out cross-validation to prevent in-sample fitting.

We can use CCM theory to ensure that the species in our data are actually displaying causal signals.

***

```{r ccm all species and physical vars, echo=F,warning=F}
# Rows hold predicted variables, columns hold forcing variables. There are more columns than rows since the physical variables are included as potential forcing factors.
n_col <- dim(westend)[2]-2
n_row <- dim(westend)[2]-7
col_names <- colnames(westend)[3:(n_col+2)]
row_names <- colnames(westend)[3:(n_row+2)]
westend.xmap_mat <- array(NA,dim=c(n_row,n_col),dimnames=list(row_names,col_names))

## CCM causation criterion 1: cross-map skill greater than zero
# matrix to store a bootstrapped p-value, measuring the probability that a given xmap is greater than zero (calculated as 1 minus the number of positive results for rho divided by the number of iterations)
westend.p1.mat <- array(NA,dim=c(n_row,n_col),dimnames=list(row_names,col_names))

## CCM causation criterion 2: evidence for convergence
# similarly, matrix to store a bootstrapped p-value, this time a t-test value between library size 10 and library size 500, to see if the rho at large library is significantly greater than the rho at small library size (i.e., looking for convergence).
westend.p2.mat <- array(NA,dim=c(n_row,n_col),dimnames=list(row_names,col_names))

# if both p1 and p2 are positive, indicate overall significant causal signal
westend.ptot.mat <- array(NA,dim=c(n_row,n_col),dimnames=list(row_names,col_names))

## Run CCM for each combination of variables
for(i in 1:n_row) {
  for(j in 1:n_col) {
    if(i != j) {
      # remember, we use the best embedding dimension for the target variable (the variable we're cross-mapping to, i.e. the putative forcing variable)
      tempE=westend.bestE[col_names[j]]
      temp <- ccm(westend,lib=as.matrix(westend.segs),pred=as.matrix(westend.segs),E=tempE,lib_column= 2+i,target_column = 2+j,lib_sizes = c(10,500),num_samples=100,replace=T,silent=T)
      # mean rho at library size 500
      rhomean <- temp %>% filter(lib_size==500) %>% ccm_means()
      westend.xmap_mat[i,j] <- rhomean$rho
      
      # first p-value (greater than zero? at library size 500)
      p1 <- temp %>% filter(lib_size==500) %>% 
        mutate(pos=ifelse(rho>0,1,0)) %>%
        summarise(p=(1-sum(pos)/n()))
      westend.p1.mat[i,j] <- as.numeric(p1)
      
      # second p-value (rho at lib-size 500 greater than rho at lib-size 10?)
      p2 <- t.test(temp$rho[temp$lib_size==10],temp$rho[temp$lib_size==500])$p.value
      westend.p2.mat[i,j] <- as.numeric(p2)
      
      # overall significance (both p1 and p2 signficant at alpha 0.05)
      westend.ptot.mat[i,j] <- ifelse(p1<0.05 & p2<0.05,1,0)
    }
  }
}
rm(n_col,n_row,col_names,row_names,p1,p2,tempE,temp,rhomean)

# keep only signficant cross-mappings
westend.xmap_mat <- westend.xmap_mat*westend.ptot.mat %>% as.data.frame()
westend.xmap_rast <- westend.xmap_mat %>% 
  mutate(predictee=row.names(westend.xmap_mat)) %>% 
  gather(key=predictor,value=rho,-predictee)

# If rho is zero, replace with NA (no significant causal signal)
westend.xmap_rast$rho[westend.xmap_rast$rho==0] <- NA

# Names for plotting to distinguish biological and physical variables
westend.xmap_rast <- westend.xmap_rast %>% 
  mutate(force.name=namekey$plotting[match(predictor,namekey$short)]) %>%
  mutate(pred.name=namekey$plotting[match(predictee,namekey$short)])

## plot
westend.xmap_all_plot <- ggplot(westend.xmap_rast,aes(x=force.name,y=pred.name,fill=rho)) +
  geom_raster() +
  scale_fill_gradient(low = "#9AFF9A", high = "#548B54", space = "Lab", na.value = "grey50", 
      guide = "colourbar",name=expression(paste(rho, "(skill)"))) +
  ggtitle("Kelp Forest Convergent Cross Mapping, West End") +
  xlab("Predictor (Forcing Variable)") +
  ylab("Predicted Variable") +
  theme(axis.text.x=element_text(angle = 90, hjust = 1,vjust=0.1))

westend.xmap_all_plot
```

The plot shows cross-mapped (predictor, or forcing) variables in the columns, while rows are predicted variables. Gray indicates a lack of significant causal signal, and darker colors represent higher cross-map skill.

From this plot, we can make a few observations. The five physical forcing variables are represented in the first five columns, followed by the algae and urchin species. Many physical variables show causal relationships with kelp forest species, especially the North Pacific Gyre Oscillation and Pacific Decadal Oscillation, which show causal links to almost all the biological variables. The NPGO is cross-mapped well by the purple urchin *Strongylocentrotus purpuratus*, while SST in turn shows a strong influence on adult *Macrocystis* dynamics. So already we are seeing effects that we might expect based on known interactions between physical variables and biological dynamics [@Reed2011;@Bell2015].

Additionally, adult *Macrocystis* itself seems to be a strong driver of the dynamics of many, if not all the other species in the tropic web, supporting the decades of research showing the importance of giant kelp as a foundational species [@Graham2007c;@Dayton1985], but further suggesting that its dynamics fundamentally drive the dynamics of other species.  Juvenile, or sporophyte *Macrocystis*, on the other hand, is affected by most of the variables in the system, but does not itself drive dynamics of other species, again an effect we would expect to find. In this system, *Pterygophora californica* also seems to be a signicant driver of the dynamics of other species in the trophic web.

Both sea urchin species are causal predictors of *Macrocystis* density, and they also have a causal effect on one another. This analysis alone, however, does not yet tell us whether the bi-directional interaction between *S. purpuratus* and *M. franciscanus* represents apparent mutualism, apparent competition, or a mixture of both at different times. To further investigate the direction and magnitude of the species interactions themselves, we next build multivariate EDM models that explicitly measure dynamic species interaction strengths.

## 3. Multivariate Models Using CCM results

For each site and each species, we'll only use the variables that show a causal link to build multivariate models, also removing those variables that did not pass diagnositic tests (simplex or prediction horizon). We find the causal variables for each species, based on the CCM output for that species.
```{r causal vars fxn,message=F,echo=F}
causal_vars <- function(pmat,vars) {
  out <- list()
  for(i in 1:length(vars)) {
    v <- vars[i]
    causes <- colnames(pmat)[pmat[v,]==1]
    causes <- causes[!is.na(causes)]
    out[[v]] <- c(causes,v)
  }
  return(out)
}
westend.causal.vars <- causal_vars(westend.ptot.mat,vars=c("mac","purp","lam","ymac","red","pter"))
```

## References